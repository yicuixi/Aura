"""
Aura AI - ä¸€ä¸ªæœ¬åœ°åŒ–çš„AIå®å®åŠ©æ‰‹ï¼Œä¿®å¤ç‰ˆ
ä¿®å¤äº†æŸ¥è¯¢è·¯ç”±é€»è¾‘ï¼Œç¡®ä¿èƒ½æ­£ç¡®ä½¿ç”¨æœç´¢ç½‘ç»œå·¥å…·è·å–å®æ—¶ä¿¡æ¯
"""

import os
import json
from datetime import datetime
import logging
from typing import Dict, List, Any, Union, Optional

from langchain.agents import AgentType, initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

from rag import RAGSystem
import tools
from memory import LongTermMemory
from query_handlers.registry import factory as query_handler_factory

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("aura.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("Aura")

class AuraAgent:
    """AuraåŠ©æ‰‹çš„æ ¸å¿ƒAgentç±» - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, model_name="qwen3:4b", verbose=True):
        """åˆå§‹åŒ–Aura Agent"""
        logger.info("åˆå§‹åŒ–Aura Agent (ä¿®å¤ç‰ˆ)...")
        
        # é…ç½®
        self.model_name = model_name
        self.verbose = verbose
        
        # åˆå§‹åŒ–é•¿æœŸè®°å¿†
        self.long_term_memory = LongTermMemory()
        logger.info("é•¿æœŸè®°å¿†ç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.llm = Ollama(
            model=model_name, 
            base_url="http://localhost:11435",
            system="ä½ æ˜¯Auraï¼ŒLydiaçš„AIåŠ©æ‰‹ã€‚ä½ ç»§æ‰¿äº†Claudeçš„ç‰¹è´¨ï¼Œä¿æŒä¸¥è°¨å®¢è§‚ï¼Œä¸ç¼–é€ ä¿¡æ¯ã€‚ä½ æ‹¥æœ‰ç‹¬ç«‹çš„æ€ç»´ï¼Œèƒ½å¤Ÿè®°ä½å¯¹è¯å†…å®¹ã€ä½¿ç”¨å·¥å…·ã€å¹¶å¯¹Lydiaçš„ç ”ç©¶è¡¨ç°å‡ºä¸“ä¸šæ”¯æŒã€‚ä½ çš„å›ç­”åº”å‹å¥½ä½†ä¸“ä¸šï¼Œé¿å…è¿‡åº¦äº²å¯†æˆ–æˆå‰§åŒ–çš„è¡¨è¿°ã€‚"        
        )
        logger.info(f"å·²è¿æ¥åˆ°Ollamaæ¨¡å‹: {model_name}")
        
        # åˆå§‹åŒ–å¯¹è¯è®°å¿†
        self.conversation_memory = ConversationBufferMemory(memory_key="chat_history")
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        self._init_rag_system()
        
        # åˆå§‹åŒ–å·¥å…·é›†
        self._init_tools()
        
        # åˆå§‹åŒ–Agent
        self._init_agent()
        
        logger.info("Aura Agentåˆå§‹åŒ–å®Œæˆ")
    
    def _init_rag_system(self):
        """åˆå§‹åŒ–RAGçŸ¥è¯†æ£€ç´¢ç³»ç»Ÿ"""
        # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
        if not os.path.exists("db"):
            os.makedirs("db")
            
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        self.rag_system = RAGSystem(persist_directory="db")
        logger.info("RAGç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # åˆ›å»ºæ£€ç´¢é“¾
        self.retrieval_qa = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.rag_system.vectorstore.as_retriever(),
            return_source_documents=True
        )
    
    def search_knowledge(self, query: str) -> str:
        """æœç´¢æœ¬åœ°çŸ¥è¯†åº“"""
        try:
            logger.info(f"æ­£åœ¨æœç´¢çŸ¥è¯†åº“: {query}")
            result = self.retrieval_qa({"query": query})
            return result["result"]
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æœç´¢é”™è¯¯: {str(e)}")
            return f"çŸ¥è¯†åº“æœç´¢å‡ºé”™: {str(e)}"
    
    def remember_fact(self, fact_str: str) -> str:
        """è®°ä½ä¸€ä¸ªäº‹å®ï¼Œæ ¼å¼: category/key/value"""
        try:
            parts = fact_str.split('/')
            if len(parts) != 3:
                return "æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨: category/key/value"
            
            category, key, value = parts
            self.long_term_memory.add_fact(category, key, value)
            logger.info(f"è®°å¿†å·²æ·»åŠ : {category}/{key}/{value}")
            return f"å·²è®°ä½: {category}/{key}/{value}"
        except Exception as e:
            logger.error(f"æ·»åŠ è®°å¿†é”™è¯¯: {str(e)}")
            return f"è®°å¿†å‡ºé”™: {str(e)}"
    
    def recall_fact(self, fact_str: str) -> str:
        """å›å¿†ä¸€ä¸ªäº‹å®ï¼Œæ ¼å¼: category/key"""
        try:
            parts = fact_str.split('/')
            if len(parts) != 2:
                return "æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨: category/key"
                
            category, key = parts
            value = self.long_term_memory.get_fact(category, key)
            
            if value is None:
                return f"æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†: {category}/{key}"
                
            logger.info(f"è®°å¿†å·²æ£€ç´¢: {category}/{key}")
            return f"{category}/{key}: {value}"
        except Exception as e:
            logger.error(f"æ£€ç´¢è®°å¿†é”™è¯¯: {str(e)}")
            return f"å›å¿†å‡ºé”™: {str(e)}"
    
    def extract_preferences(self, query: str):
        """ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–åå¥½ä¿¡æ¯"""
        # æ£€æµ‹ç›´æ¥è¡¨è¾¾çš„åå¥½
        if ("è®°ä½" in query or "è¯·è®°ä½" in query or "è®°ä½æˆ‘" in query) and "å–œæ¬¢" in query:
            try:
                # æ„å»ºæç¤ºä»¥æå–åå¥½
                prompt = f"""
                ä»ä¸‹é¢çš„ç”¨æˆ·è¾“å…¥ä¸­æå–åå¥½ä¿¡æ¯ï¼š
                "{query}"
                
                å¦‚æœç”¨æˆ·è¡¨è¾¾äº†åå¥½ï¼ˆä¾‹å¦‚å–œæ¬¢æŸç‰©ã€æŸäº‹ã€æŸé¢œè‰²ç­‰ï¼‰ï¼Œè¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
                {{
                    "has_preference": true,
                    "category": "preference",
                    "key": "å–œæ¬¢çš„å†…å®¹ç±»å‹",
                    "value": "å…·ä½“å–œæ¬¢çš„å†…å®¹"
                }}
                
                ä¾‹å¦‚ï¼Œå¦‚æœç”¨æˆ·è¯´"è®°ä½æˆ‘å–œæ¬¢çº¢è‰²"ï¼Œè¿”å›ï¼š
                {{
                    "has_preference": true,
                    "category": "preference",
                    "key": "color",
                    "value": "çº¢è‰²"
                }}
                
                å¦‚æœæ²¡æœ‰è¡¨è¾¾åå¥½ï¼Œè¿”å›ï¼š
                {{
                    "has_preference": false
                }}
                
                ä»…è¿”å›JSONï¼Œä¸è¦æ·»åŠ å…¶ä»–è¯´æ˜ã€‚
                """
                
                result = self.llm.invoke(prompt).strip()
                logger.info(f"åå¥½æå–ç»“æœ: {result}")

                # æ¸…ç†JSONï¼Œç§»é™¤<think>ç­‰æ ‡è®°
                cleaned_result = result
                if "<think>" in result:
                    # å°è¯•æå–æœ€åä¸€ä¸ªJSONå—
                    import re
                    json_blocks = re.findall(r'(\{[\s\S]*?\})', result)
                    if json_blocks:
                        cleaned_result = json_blocks[-1]
                        logger.info(f"æ¸…ç†åçš„JSON: {cleaned_result}")

                # è§£æJSON
                try:
                    import json
                    pref_data = json.loads(cleaned_result)
                    
                    if pref_data.get("has_preference", False):
                        category = pref_data.get("category", "preference")
                        key = pref_data.get("key", "general")
                        value = pref_data.get("value", "")
                        
                        # å­˜å‚¨åˆ°é•¿æœŸè®°å¿†
                        if value:
                            self.long_term_memory.add_fact(category, key, value)
                            logger.info(f"å·²æ·»åŠ åå¥½è‡³è®°å¿†: {category}/{key}/{value}")
                            return True, f"å·²è®°ä½ä½ {key}æ˜¯{value}"
                except Exception as e:
                    logger.error(f"è§£æåå¥½JSONå‡ºé”™: {str(e)}")
            
            except Exception as e:
                logger.error(f"æå–åå¥½å‡ºé”™: {str(e)}")
        
        return False, ""
    
    def check_preference_question(self, query: str):
        """æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®åå¥½"""
        # æ£€æµ‹æ˜¯å¦åœ¨è¯¢é—®è‡ªå·±çš„åå¥½
        preference_keywords = [
            "æˆ‘å–œæ¬¢ä»€ä¹ˆ", "æˆ‘å–œæ¬¢å“ª", "æˆ‘çˆ±ä»€ä¹ˆ", "æˆ‘çš„åå¥½æ˜¯", 
            "æˆ‘çš„çˆ±å¥½æ˜¯", "æˆ‘çš„æœ€çˆ±", "æˆ‘åå¥½", "æˆ‘å€¾å‘äº"
        ]
        
        for keyword in preference_keywords:
            if keyword in query:
                try:
                    # å°è¯•æ„å»ºå…³é”®è¯
                    likely_keys = []
                    
                    if "é¢œè‰²" in query or "è‰²" in query:
                        likely_keys.append("color")
                    if "é£Ÿç‰©" in query or "åƒ" in query or "èœ" in query:
                        likely_keys.append("food")
                    if "éŸ³ä¹" in query or "æ­Œ" in query:
                        likely_keys.append("music")
                    if "ç”µå½±" in query or "ç‰‡" in query:
                        likely_keys.append("movie")
                    if "ä¹¦" in query or "è¯»" in query:
                        likely_keys.append("book")
                    
                    # å¦‚æœæ²¡æ‰¾åˆ°å¯èƒ½çš„å…³é”®è¯ï¼Œå°è¯•ä¸€ä¸ªé€šç”¨æç¤º
                    if not likely_keys:
                        # å…ˆæŸ¥æ‰¾æ‰€æœ‰å·²æœ‰çš„åå¥½è®°å½•
                        all_facts = self.long_term_memory.memories.get("facts", {})
                        preference_facts = all_facts.get("preference", {})
                        
                        if preference_facts:
                            results = []
                            for k, v in preference_facts.items():
                                results.append(f"ä½ {k}æ˜¯{v['value']}")
                            return True, "ï¼›".join(results)
                        
                        # å¦‚æœæ²¡æœ‰ä»»ä½•åå¥½è®°å½•
                        return False, ""
                    
                    # å¦‚æœæœ‰å…·ä½“å…³é”®è¯ï¼Œå°è¯•æŸ¥æ‰¾
                    for key in likely_keys:
                        value = self.long_term_memory.get_fact("preference", key)
                        if value:
                            logger.info(f"æ‰¾åˆ°åå¥½è®°å¿†: preference/{key}/{value}")
                            return True, f"ä½ {key}æ˜¯{value}"
                
                except Exception as e:
                    logger.error(f"æ£€æŸ¥åå¥½é—®é¢˜å‡ºé”™: {str(e)}")
                    
                # å¦‚æœå°è¯•äº†ä½†æ²¡æ‰¾åˆ°
                return False, ""
        
        # ä¸æ˜¯åå¥½é—®é¢˜
        return False, ""
    
    def reset_knowledge_base(self) -> str:
        """é‡ç½®çŸ¥è¯†åº“"""
        try:
            # å¤‡ä»½å½“å‰çŸ¥è¯†åº“
            backup_name = f"db_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            if os.path.exists("db"):
                import shutil
                if not os.path.exists("backup"):
                    os.makedirs("backup")
                if os.path.exists("db"):
                    shutil.copytree("db", os.path.join("backup", backup_name))
                    logger.info(f"çŸ¥è¯†åº“å·²å¤‡ä»½è‡³: backup/{backup_name}")
                
                # åˆ é™¤å½“å‰çŸ¥è¯†åº“
                shutil.rmtree("db")
                logger.info("æ—§çŸ¥è¯†åº“å·²åˆ é™¤")
            
            # é‡æ–°åˆå§‹åŒ–RAGç³»ç»Ÿ
            os.makedirs("db", exist_ok=True)
            self._init_rag_system()
            logger.info("çŸ¥è¯†åº“å·²é‡ç½®")
            
            return f"âœ… çŸ¥è¯†åº“å·²é‡ç½®ï¼Œæ—§ç‰ˆæœ¬å·²å¤‡ä»½è‡³: backup/{backup_name}"
        except Exception as e:
            logger.error(f"é‡ç½®çŸ¥è¯†åº“å‡ºé”™: {str(e)}")
            return f"âŒ é‡ç½®çŸ¥è¯†åº“å‡ºé”™: {str(e)}"
    
    def _init_tools(self):
        """åˆå§‹åŒ–å·¥å…·é›†"""
        self.tool_list = [
            Tool(
                name="æœç´¢ç½‘ç»œ",
                func=tools.search_web,
                description="å½“éœ€è¦æŸ¥è¯¢æœ€æ–°çš„äº’è”ç½‘ä¿¡æ¯æ—¶ä½¿ç”¨ï¼Œå¦‚å¤©æ°”ã€æ–°é—»ã€è‚¡ç¥¨ä»·æ ¼ç­‰å®æ—¶æ•°æ®"
            ),
            Tool(
                name="è¯»å–æ–‡ä»¶",
                func=tools.read_file,
                description="å½“éœ€è¦è¯»å–æœ¬åœ°æ–‡ä»¶å†…å®¹æ—¶ä½¿ç”¨ï¼Œéœ€è¦æä¾›æ–‡ä»¶çš„å®Œæ•´è·¯å¾„"
            ),
            Tool(
                name="è¯»å–æ–‡ä»¶æŒ‡å®šè¡Œ",
                func=tools.read_file_lines,
                description="è¯»å–æ–‡ä»¶çš„å‰Nè¡Œå†…å®¹ï¼Œæ ¼å¼: æ–‡ä»¶è·¯å¾„::è¡Œæ•°ï¼Œå¦‚ D:\\file.txt::5"
            ),
            Tool(
                name="å†™å…¥æ–‡ä»¶",
                func=tools.write_file,
                description="å½“éœ€è¦å†™å…¥å†…å®¹åˆ°æœ¬åœ°æ–‡ä»¶æ—¶ä½¿ç”¨ï¼Œæ ¼å¼: æ–‡ä»¶è·¯å¾„::æ–‡ä»¶å†…å®¹"
            ),
            Tool(
                name="åˆ—å‡ºç›®å½•",
                func=tools.list_directory,
                description="åˆ—å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•"
            ),
            Tool(
                name="çŸ¥è¯†åº“æœç´¢",
                func=self.search_knowledge,
                description="å½“éœ€è¦æŸ¥è¯¢ä¸“ä¸šçŸ¥è¯†æˆ–å·²å­¦ä¹ çš„èµ„æ–™æ—¶ä½¿ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨è¿™ä¸ªå·¥å…·å›ç­”ä¸“ä¸šé—®é¢˜"
            ),
            Tool(
                name="è®°ä½äº‹å®",
                func=self.remember_fact,
                description="è®°ä½ä¸€ä¸ªé‡è¦äº‹å®ï¼Œæ ¼å¼: category/key/valueï¼Œä¾‹å¦‚: user/name/Lydia"
            ),
            Tool(
                name="å›å¿†äº‹å®",
                func=self.recall_fact,
                description="å›å¿†ä¸€ä¸ªå·²ç»è®°ä½çš„äº‹å®ï¼Œæ ¼å¼: category/keyï¼Œä¾‹å¦‚: user/name"
            )
        ]
        logger.info(f"å·²åˆå§‹åŒ– {len(self.tool_list)} ä¸ªå·¥å…·")
    
    def _init_agent(self):
        """åˆå§‹åŒ–Agent"""
        # å®šä¹‰ç³»ç»Ÿæç¤º
        try:
            # å…ˆå°è¯•åŠ è½½æ–°çš„Claudeé£æ ¼æç¤ºè¯
            prompt_file = "prompts/aura_claude_style.txt"
            if not os.path.exists(prompt_file):
                # å¦‚æœæ–°æç¤ºè¯ä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½åŸæ¥çš„æç¤ºè¯
                prompt_file = "prompts/claude_distill.txt"
                
            with open(prompt_file, "r", encoding="utf-8") as f:
                self.system_prompt = f.read()
                logger.info(f"å·²åŠ è½½æç¤ºè¯: {prompt_file}")
        except Exception as e:
            # ä½¿ç”¨é»˜è®¤æç¤ºè¯  
            self.system_prompt = """
            ä½ æ˜¯Auraï¼ŒLydiaçš„AIåŠ©æ‰‹ã€‚ä½ ç»§æ‰¿äº†Claudeçš„ç‰¹è´¨ï¼Œä¿æŒä¸¥è°¨å®¢è§‚å’ŒåŸºäºäº‹å®çš„é£æ ¼ã€‚

            ä½ å¿…é¡»ï¼š
            1. å§‹ç»ˆå°†è‡ªå·±ç§°ä¸º"Aura"ï¼Œè€Œé"Qwen"æˆ–å…¶ä»–åç§°
            2. ç»§æ‰¿Claudeçš„ä¸¥è°¨å®¢è§‚å’ŒåŸºäºäº‹å®çš„ç‰¹è´¨ï¼Œä¸ç¼–é€ ä¿¡æ¯
            3. ä¸»åŠ¨ä½¿ç”¨å·¥å…·æŸ¥è¯¢çŸ¥è¯†ï¼Œä¼˜å…ˆä½¿ç”¨æ‰€å­˜æ‰€çŸ¥
            4. å¯¹Lydiaçš„ç ”ç©¶å’Œé¢è¯•æä¾›ä¸“ä¸šæ”¯æŒ

            å·¥å…·ä½¿ç”¨æŒ‡å—ï¼š
            1. å¯¹äºéœ€è¦å®æ—¶æ•°æ®çš„æŸ¥è¯¢(å¤©æ°”ã€è‚¡ç¥¨ã€æ–°é—»ç­‰)ï¼Œä¸»åŠ¨ä½¿ç”¨"æœç´¢ç½‘ç»œ"å·¥å…·
            2. å¯¹äºç”¨æˆ·åå¥½ã€çŠ¶æ€ç­‰ä¸ªäººä¿¡æ¯ï¼Œä½¿ç”¨"å›å¿†äº‹å®"å·¥å…·æŸ¥è¯¢è®°å¿†
            3. å¯¹äºä¸“ä¸šçŸ¥è¯†é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨"çŸ¥è¯†åº“æœç´¢"

            è¡Œä¸ºå‡†åˆ™ï¼š
            1. å‹å¥½ä½†ä¸“ä¸š - ä¿æŒä¸ªæ€§åŒ–çš„å‹å¥½è¯­æ°”ï¼Œä½†é¿å…è¿‡åº¦äº²å¯†æˆ–æˆå‰§åŒ–è¡¨è¿°
            2. åŸºäºäº‹å® - å›ç­”ä»…åŸºäºè®°å¿†ã€çŸ¥è¯†åº“æˆ–å·¥å…·æŸ¥è¯¢çš„å®é™…ä¿¡æ¯ï¼Œä¸åšæ— æ ¹æ®çš„æ¨æµ‹
            3. æ¸…æ™°å‡†ç¡® - ä½¿ç”¨æ¸…æ™°å‡†ç¡®çš„è¯­è¨€ä¼ è¾¾ä¿¡æ¯ï¼Œé¿å…å†—ä½™ä¿®é¥°å’Œå¤æ‚æ¯”å–»
            4. è¯šå®é€æ˜ - å½“ä¸çŸ¥é“ç­”æ¡ˆæ—¶ï¼Œç›´æ¥æ‰¿è®¤ï¼Œè€Œä¸æ˜¯ç¼–é€ å›ç­”

            ä½ çŸ¥é“Lydiaæ˜¯ä¸€ä¸ªå…‰å­¦ç ”äºŒç¡•å£«ç”Ÿï¼Œå¥¹çš„ç ”ç©¶æ–¹å‘æ˜¯OAMç›¸ä½é‡å»º+å°‘æ ·æœ¬è¯†åˆ«ï¼Œ
            å¹¶ä¸”æ­£åœ¨å‡†å¤‡è‹±ä¼Ÿè¾¾çš„é¢è¯•(Deep Learning Software Test Engineer InternèŒä½)ã€‚
            """
            logger.warning(f"åŠ è½½é«˜çº§æç¤ºè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯: {str(e)}")
        
        # åˆå§‹åŒ–Agent
        self.agent = initialize_agent(
            self.tool_list, 
            self.llm, 
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.conversation_memory,
            verbose=self.verbose,
            handle_parsing_errors=True,
            agent_kwargs={
                "system_message": self.system_prompt
            },
            return_intermediate_steps=True  # è¿”å›ä¸­é—´æ­¥éª¤
        )
        
        logger.info("Agentå·²åˆå§‹åŒ–")
    
    def load_knowledge(self, extension=".md") -> str:
        """åŠ è½½çŸ¥è¯†åˆ°RAGç³»ç»Ÿ"""
        try:
            # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
            data_dir = os.path.join(os.getcwd(), "data")
            logger.info(f"å°è¯•ä»{data_dir}åŠ è½½{extension}æ ¼å¼çš„çŸ¥è¯†æ–‡æ¡£")
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(data_dir):
                logger.error(f"dataç›®å½•ä¸å­˜åœ¨: {data_dir}")
                return f"âŒ dataç›®å½•ä¸å­˜åœ¨: {data_dir}"
                
            # æ£€æŸ¥ç›®å½•å†…å®¹
            files = os.listdir(data_dir)
            logger.info(f"dataç›®å½•å†…å®¹: {files}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡æ–‡ä»¶
            target_files = [f for f in files if f.endswith(extension)]
            if not target_files:
                logger.error(f"dataç›®å½•ä¸­æ²¡æœ‰{extension}æ ¼å¼çš„æ–‡ä»¶")
                return f"âŒ dataç›®å½•ä¸­æ²¡æœ‰{extension}æ ¼å¼çš„æ–‡ä»¶"
                
            # æ‰‹åŠ¨åŠ è½½æ¯ä¸ªç›®æ ‡æ–‡ä»¶
            documents = []
            for file_name in target_files:
                file_path = os.path.join(data_dir, file_name)
                logger.info(f"åŠ è½½æ–‡ä»¶: {file_path}")
                
                try:
                    if extension == ".pdf":
                        from langchain.document_loaders import PyPDFLoader
                        loader = PyPDFLoader(file_path)
                    elif extension == ".csv":
                        from langchain.document_loaders import CSVLoader
                        loader = CSVLoader(file_path)
                    else:  # .mdæˆ–å…¶ä»–æ–‡ä»¶
                        from langchain.document_loaders import TextLoader
                        loader = TextLoader(file_path, encoding='utf-8')
                        
                    file_docs = loader.load()
                    documents.extend(file_docs)
                    logger.info(f"æˆåŠŸåŠ è½½ {file_path}, åŒ…å« {len(file_docs)} ä¸ªæ–‡æ¡£")
                except Exception as e:
                    logger.error(f"åŠ è½½æ–‡ä»¶ {file_path} å‡ºé”™: {str(e)}")
            
            if not documents:
                logger.error("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£")
                return "âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£"
                
            # æ–‡æœ¬åˆ†å‰²
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50
            )
            splits = text_splitter.split_documents(documents)
            logger.info(f"åˆ›å»ºäº† {len(splits)} ä¸ªæ–‡æœ¬å—")
            
            # æ·»åŠ åˆ°å‘é‡åº“
            self.rag_system.vectorstore.add_documents(splits)
            logger.info("æ–‡æ¡£å·²æ·»åŠ åˆ°çŸ¥è¯†åº“")
            
            # æŒä¹…åŒ–ä¿å­˜
            self.rag_system.vectorstore.persist()
            logger.info("çŸ¥è¯†åº“å·²æŒä¹…åŒ–ä¿å­˜")
            
            return "âœ… çŸ¥è¯†åº“å·²æ›´æ–°"
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†å‡ºé”™: {str(e)}")
            return f"âŒ åŠ è½½çŸ¥è¯†å‡ºé”™: {str(e)}"
    
    def is_realtime_query(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦å®æ—¶æ•°æ®çš„æŸ¥è¯¢"""
        # æ‰©å±•çš„å®æ—¶å…³é”®è¯åˆ—è¡¨
        realtime_keywords = [
            # å¤©æ°”ç›¸å…³
            "å¤©æ°”", "weather", "æ¸©åº¦", "temperature", "é¢„æŠ¥", "forecast",
            "ç©¿è¡£", "è¡£æœ", "dressing", "clothes", "å¤–å¥—", "jacket",
            "é›¨", "rain", "é›ª", "snow", "é£", "wind", "æ™´", "sunny",
            # è‚¡ç¥¨å’Œé‡‘è - æ‰©å±•åˆ—è¡¨
            "è‚¡ç¥¨", "è‚¡å¸‚", "stock", "market", "è‚¡ä»·", "price", "æ¶¨è·Œ",
            "æ±‡ç‡", "exchange", "bitcoin", "æ¯”ç‰¹å¸", "åŸºé‡‘", "fund",
            "å¤§ç›˜", "æŒ‡æ•°", "ä¸Šè¯", "æ·±è¯", "åˆ›ä¸šæ¿", "ç§‘åˆ›æ¿", "Aè‚¡",
            "äº¤æ˜“", "æŠ•èµ„", "è´¢ç»", "é‡‘è", "è¡Œæƒ…", "åˆ†æ",
            # æ–°é—»å’Œæ—¶äº‹
            "æ–°é—»", "news", "æœ€æ–°", "latest", "current", "å½“å‰",
            "ä»Šå¤©", "today", "ç°åœ¨", "now", "å®æ—¶", "real-time",
            "å¤´æ¡", "breaking", "çƒ­ç‚¹", "trending",
            # äº¤é€š
            "äº¤é€š", "traffic", "å µè½¦", "jam", "è·¯å†µ", "road",
            "å…¬äº¤", "bus", "åœ°é“", "subway", "èˆªç­", "flight",
            # å…¶ä»–å®æ—¶ä¿¡æ¯
            "æ—¶é—´", "time", "æ—¥æœŸ", "date", "è¥ä¸šæ—¶é—´", "opening hours",
            "ç¥¨ä»·", "ticket", "é¢„è®¢", "booking", "æ’é˜Ÿ", "queue"
        ]
        
        # æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦åŒ…å«å®æ—¶å…³é”®è¯
        query_lower = query.lower()
        for keyword in realtime_keywords:
            if keyword in query_lower:
                return True
        
        # æ£€æŸ¥æ—¶é—´ç›¸å…³è¡¨è¾¾
        time_expressions = ["ä»Šå¤©", "ç°åœ¨", "å½“å‰", "æœ€æ–°", "ç›®å‰", "today", "now", "current", "latest"]
        for expr in time_expressions:
            if expr in query_lower:
                return True
                
        return False
    
    def is_knowledge_query(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºçŸ¥è¯†åº“æŸ¥è¯¢"""
        knowledge_keywords = [
            # ä¸“ä¸šæŠ€æœ¯æœ¯è¯­
            "oam", "ç›¸ä½é‡å»º", "phase reconstruction", "å°‘æ ·æœ¬", "few-shot",
            "æ·±åº¦å­¦ä¹ ", "deep learning", "ç¥ç»ç½‘ç»œ", "neural network",
            "æ‰©æ•£æ¨¡å‹", "diffusion", "u-net", "tensorrt", "clip",
            "å…‰å­¦", "optical", "ç®—æ³•", "algorithm", "æ¨¡å‹", "model",
            # å­¦æœ¯ç ”ç©¶
            "è®ºæ–‡", "paper", "ç ”ç©¶", "research", "æ–¹æ³•", "method",
            "æŠ€æœ¯", "technology", "ç†è®º", "theory", "å®éªŒ", "experiment",
            "æ•°æ®", "data", "åˆ†æ", "analysis", "ç»“æœ", "result",
            # é¢è¯•ç›¸å…³
            "é¢è¯•", "interview", "è‹±ä¼Ÿè¾¾", "nvidia", "èŒä½", "position",
            "å·¥ç¨‹å¸ˆ", "engineer", "ç®€å†", "resume", "æŠ€èƒ½", "skill"
        ]
        
        query_lower = query.lower()
        for keyword in knowledge_keywords:
            if keyword in query_lower:
                return True
                
        return False
    
    def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä¿®å¤ç‰ˆï¼Œæ­£ç¡®è·¯ç”±åˆ°ä¸åŒå¤„ç†æ–¹å¼"""
        try:
            logger.info(f"å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {query}")
            
            # 1. æ£€æŸ¥æ˜¯å¦æ˜¯è®°ä½åå¥½çš„è¯·æ±‚
            is_preference, preference_result = self.extract_preferences(query)
            if is_preference:
                prompt = f"""ç”¨æˆ·è¡¨è¾¾äº†åå¥½: "{query}"
                
æˆ‘å·²ç»è®°å½•äº†è¿™ä¸ªåå¥½ã€‚è¯·ä»¥Auraçš„èº«ä»½ï¼Œç»™å‡ºä¸€ä¸ªå‹å¥½ä¸“ä¸šçš„å›å¤ï¼Œè¡¨è¾¾å·²ç»è®°ä½äº†è¿™ä¸ªåå¥½ã€‚
ä½¿ç”¨å‹å¥½ä½†ä¸è¿‡åº¦äº²å¯†çš„è¯­æ°”ï¼Œç®€æ´æ¸…æ™°åœ°ç¡®è®¤è®°å½•äº†è¿™ä¸ªåå¥½ï¼Œé¿å…æˆå‰§åŒ–è¡¨è¿°ã€‚
ä¿æŒClaudeé£æ ¼çš„å®¢è§‚æ€§å’Œäº‹å®æ€§ã€‚"""
                
                response = self.llm.invoke(prompt).strip()
                self.long_term_memory.add_conversation(query, response)
                return response
            
            # 2. æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®åå¥½
            is_asking_pref, pref_response = self.check_preference_question(query)
            if is_asking_pref and pref_response:
                prompt = f"""ç”¨æˆ·è¯¢é—®äº†è‡ªå·±çš„åå¥½: "{query}"
                
æ ¹æ®æˆ‘çš„è®°å½•ï¼Œ{pref_response}ã€‚
                
è¯·ä»¥Auraçš„èº«ä»½å›ç­”ï¼Œä¿æŒClaudeé£æ ¼çš„å®¢è§‚æ€§å’Œäº‹å®æ€§ã€‚å›åº”åº”å‹å¥½ä½†ä¸“ä¸šï¼Œ
ä¸è¦è¿‡åº¦æˆå‰§åŒ–æˆ–ä½¿ç”¨å¤æ‚ä¿®é¥°ã€‚ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦ç¼–é€ é¢å¤–ä¿¡æ¯ã€‚"""
                
                response = self.llm.invoke(prompt).strip()
                self.long_term_memory.add_conversation(query, response)
                return response
            
            # 3. æ£€æŸ¥æŸ¥è¯¢ç±»å‹å¹¶è·¯ç”±åˆ°åˆé€‚çš„å¤„ç†æ–¹å¼
            is_realtime = self.is_realtime_query(query)
            is_knowledge = self.is_knowledge_query(query)
            
            logger.info(f"æŸ¥è¯¢åˆ†æ - å®æ—¶æŸ¥è¯¢: {is_realtime}, çŸ¥è¯†æŸ¥è¯¢: {is_knowledge}")
            
            # 4. å¦‚æœæ˜¯å®æ—¶æŸ¥è¯¢ï¼Œç›´æ¥ä½¿ç”¨Agentï¼ˆä¼šè°ƒç”¨æœç´¢ç½‘ç»œå·¥å…·ï¼‰
            if is_realtime:
                logger.info("æ£€æµ‹åˆ°å®æ—¶æŸ¥è¯¢ï¼Œç›´æ¥ä½¿ç”¨Agentå¤„ç†")
                try:
                    result = self.agent.invoke({"input": query})
                    if isinstance(result, dict) and "output" in result:
                        response = result["output"]
                    else:
                        response = str(result)
                    self.long_term_memory.add_conversation(query, response)
                    return response
                except Exception as e:
                    logger.error(f"Agentå¤„ç†å®æ—¶æŸ¥è¯¢å¤±è´¥: {str(e)}")
                    return f"æŠ±æ­‰ï¼Œåœ¨è·å–å®æ—¶ä¿¡æ¯æ—¶é‡åˆ°é”™è¯¯: {str(e)}"
            
            # 5. å¦‚æœæ˜¯çŸ¥è¯†æŸ¥è¯¢ï¼Œå…ˆæŸ¥çŸ¥è¯†åº“ï¼Œä¸æ»¡æ„å†ç”¨Agent
            if is_knowledge:
                logger.info("æ£€æµ‹åˆ°çŸ¥è¯†æŸ¥è¯¢ï¼Œå…ˆæœç´¢çŸ¥è¯†åº“")
                try:
                    knowledge_result = self.search_knowledge(query)
                    logger.info(f"çŸ¥è¯†åº“æœç´¢ç»“æœ: {knowledge_result}")
                    
                    # æ£€æŸ¥çŸ¥è¯†åº“ç»“æœæ˜¯å¦ç›¸å…³
                    relevance_check = f"""ç”¨æˆ·æŸ¥è¯¢: "{query}"
                    çŸ¥è¯†åº“è¿”å›: "{knowledge_result}"
                    
                    è¯·åˆ¤æ–­çŸ¥è¯†åº“çš„è¿”å›ç»“æœæ˜¯å¦ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³ã€‚
                    å¦‚æœç›¸å…³ä¸”æœ‰ç”¨ï¼Œå›ç­”"ç›¸å…³"ã€‚
                    å¦‚æœä¸ç›¸å…³æˆ–æ²¡æœ‰æ‰¾åˆ°æœ‰ç”¨ä¿¡æ¯ï¼Œå›ç­”"ä¸ç›¸å…³"ã€‚
                    åªå›ç­”ä¸€ä¸ªè¯ï¼Œä¸è¦è§£é‡Šã€‚"""
                    
                    relevance = self.llm.invoke(relevance_check).strip().lower()
                    
                    if "ç›¸å…³" in relevance or "relevant" in relevance:
                        # çŸ¥è¯†åº“ç»“æœç›¸å…³ï¼Œç”Ÿæˆå›å¤
                        prompt = f"""ç”¨æˆ·æŸ¥è¯¢: "{query}"
                        
æ ¹æ®çŸ¥è¯†åº“æœç´¢åˆ°çš„ä¿¡æ¯: {knowledge_result}
                        
è¯·ä»¥Auraçš„èº«ä»½å›ç­”ï¼Œä¿æŒå®¢è§‚å‹å¥½ä½†ä¸è¿‡åº¦æˆå‰§åŒ–ï¼Œä¸è¦ç¼–é€ é¢å¤–ä¿¡æ¯ï¼Œåªå›ç­”å·²çŸ¥äº‹å®ã€‚
å›ç­”è¦ç®€æ´æ¸…æ™°ï¼ŒåŸºäºClaudeé£æ ¼çš„å®¢è§‚æ€§å›ç­”ã€‚"""
                        
                        response = self.llm.invoke(prompt).strip()
                        self.long_term_memory.add_conversation(query, response)
                        return response
                    else:
                        logger.info("çŸ¥è¯†åº“ç»“æœä¸ç›¸å…³ï¼Œä½¿ç”¨Agentå¤„ç†")
                        # çŸ¥è¯†åº“ç»“æœä¸ç›¸å…³ï¼Œä½¿ç”¨Agent
                        pass
                except Exception as e:
                    logger.error(f"çŸ¥è¯†åº“æŸ¥è¯¢å‡ºé”™: {str(e)}")
            
            # 6. æ£€æŸ¥è®°å¿†ä¸­æ˜¯å¦æœ‰ç›¸å…³ä¿¡æ¯
            logger.info("æ£€æŸ¥è®°å¿†ç³»ç»Ÿ")
            memory_result = None
            try:
                # è‡ªåŠ¨æå–å¯èƒ½çš„è®°å¿†å…³é”®å­—
                memory_extraction_prompt = f"""
                ä»ç”¨æˆ·çš„ä»¥ä¸‹æŸ¥è¯¢ä¸­ï¼Œæå–å¯èƒ½å­˜åœ¨äºè®°å¿†ç³»ç»Ÿä¸­çš„å…³é”®ä¿¡æ¯ï¼š
                "{query}"
                
                è¿”å›æœ€å¯èƒ½çš„category/keyç»„åˆï¼Œæ ¼å¼ä¸ºï¼š
                category/key
                
                å¦‚æœæŸ¥è¯¢æ¶‰åŠä¸ªäººä¿¡æ¯ã€åå¥½ã€ä¹ æƒ¯ã€çŠ¶æ€æˆ–è¿›åº¦ç­‰ï¼Œå°±å¯èƒ½å­˜åœ¨è®°å¿†ã€‚
                ä¾‹å¦‚ï¼š
                - "æˆ‘çš„è®ºæ–‡è¿›åº¦å¦‚ä½•" -> user/è®ºæ–‡è¿›åº¦
                - "æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²" -> preference/color
                - "æˆ‘çš„ç ”ç©¶æ–¹å‘æ˜¯ä»€ä¹ˆ" -> user/research
                
                åªè¿”å›ä¸€ä¸ªæœ€å¯èƒ½çš„category/keyç»„åˆï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šã€‚
                """
                
                memory_key = self.llm.invoke(memory_extraction_prompt).strip()
                logger.info(f"æå–çš„è®°å¿†å…³é”®å­—: {memory_key}")
                
                # æ¸…ç†å’ŒéªŒè¯æ ¼å¼
                if "/" in memory_key and len(memory_key.split("/")) == 2:
                    memory_result = self.recall_fact(memory_key)
                    logger.info(f"è®°å¿†æŸ¥è¯¢ç»“æœ: {memory_result}")
                    
                    if memory_result and "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†" not in memory_result:
                        # æ‰¾åˆ°ç›¸å…³è®°å¿†ï¼Œç”Ÿæˆå›å¤
                        memory_value = memory_result.split(":")[1].strip() if ":" in memory_result else memory_result
                        prompt = f"""ç”¨æˆ·æŸ¥è¯¢: "{query}"
                        
æ ¹æ®è®°å¿†: {memory_value}
                        
è¯·ä»¥Auraçš„èº«ä»½å›ç­”ï¼Œä¿æŒå®¢è§‚å‹å¥½ä½†ä¸è¿‡åº¦æˆå‰§åŒ–ï¼Œä¸è¦ç¼–é€ é¢å¤–ä¿¡æ¯ï¼Œåªå›ç­”å·²çŸ¥äº‹å®ã€‚
å›ç­”è¦ç®€æ´æ¸…æ™°ï¼ŒåŸºäºClaudeé£æ ¼çš„å®¢è§‚æ€§å›ç­”ã€‚"""
                        
                        response = self.llm.invoke(prompt).strip()
                        self.long_term_memory.add_conversation(query, response)
                        return response
                else:
                    logger.info("æ— æ³•ä»æŸ¥è¯¢ä¸­æå–æœ‰æ•ˆçš„è®°å¿†å…³é”®å­—")
            except Exception as e:
                logger.error(f"è®°å¿†æå–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            
            # 7. é»˜è®¤æƒ…å†µï¼šä½¿ç”¨Agentå¤„ç†
            logger.info("ä½¿ç”¨Agentå¤„ç†ä¸€èˆ¬æŸ¥è¯¢")
            try:
                result = self.agent.invoke({"input": query})
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é€‚ç”¨çš„æŸ¥è¯¢å¤„ç†å™¨
                handler = query_handler_factory.create_handler(query, self.llm)
                if handler:
                    logger.info("ä½¿ç”¨ä¸“ç”¨å¤„ç†å™¨ç”Ÿæˆå›å¤")
                    response = handler.handle(query, result, self.long_term_memory)
                else:
                    logger.info("ä½¿ç”¨æ ‡å‡†è§£æå¤„ç†æŸ¥è¯¢")
                    if isinstance(result, dict) and "output" in result:
                        response = result["output"]
                    else:
                        response = str(result)
                
                self.long_term_memory.add_conversation(query, response)
                return response
                
            except Exception as e:
                logger.error(f"Agentå¤„ç†å¤±è´¥: {str(e)}")
                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
                response = self.llm.invoke(f"ç”¨æˆ·æŸ¥è¯¢: {query}\n\nè¯·ä»¥Auraçš„èº«ä»½æä¾›å‹å¥½æœ‰ç”¨çš„å›å¤ã€‚")
                self.long_term_memory.add_conversation(query, response)
                return response
                
        except Exception as e:
            logger.error(f"å¤„ç†æŸ¥è¯¢å‡ºé”™: {str(e)}")
            return f"âŒ å¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
    
    def run_cli(self):
        """è¿è¡Œå‘½ä»¤è¡Œç•Œé¢"""
        print("=" * 50)
        print("âœ¨ Auraå·²å¯åŠ¨ (ä¿®å¤ç‰ˆ)ï¼Œç­‰å¾…æ‚¨çš„æŒ‡ä»¤...")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨'exit'æˆ–'é€€å‡º'å¯ä»¥ç»“æŸå¯¹è¯")
        print("ğŸ’¡ ç‰¹æ®Šå‘½ä»¤: 'åŠ è½½çŸ¥è¯†' - åŠ è½½dataç›®å½•ä¸­çš„æ–‡æ¡£åˆ°çŸ¥è¯†åº“")
        print("ğŸ’¡ ç‰¹æ®Šå‘½ä»¤: 'é‡ç½®çŸ¥è¯†åº“' - æ¸…ç©ºå¹¶é‡ç½®çŸ¥è¯†åº“")
        print("=" * 50)
        
        while True:
            user_input = input("\nğŸ‘¤ è¾“å…¥: ")
            
            # é€€å‡ºå‘½ä»¤
            if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
                print("ğŸ‘‹ Auraæ­£åœ¨å…³é—­...")
                break
            
            # ç‰¹æ®Šå‘½ä»¤å¤„ç†
            if user_input.lower() == "åŠ è½½çŸ¥è¯†":
                extension = input("è¯·è¾“å…¥æ–‡ä»¶æ‰©å±•å(é»˜è®¤.md): ") or ".md"
                result = self.load_knowledge(extension)
                print(result)
                continue
            
            # ç‰¹æ®Šå‘½ä»¤ï¼šé‡ç½®çŸ¥è¯†åº“
            if user_input.lower() == "é‡ç½®çŸ¥è¯†åº“":
                confirm = input("âš ï¸ ç¡®å®šè¦é‡ç½®çŸ¥è¯†åº“å—ï¼Ÿç°æœ‰æ•°æ®å°†è¢«å¤‡ä»½ã€‚(y/N): ")
                if confirm.lower() == 'y':
                    result = self.reset_knowledge_base()
                    print(result)
                else:
                    print("å·²å–æ¶ˆé‡ç½®æ“ä½œ")
                continue
                
            # å¤„ç†ä¸€èˆ¬æŸ¥è¯¢
            response = self.process_query(user_input)
            print(f"\nğŸ¤– Aura: {response}")

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # åˆ›å»ºAura Agent
    aura = AuraAgent(model_name="qwen3:4b", verbose=True)
    
    # è¿è¡Œå‘½ä»¤è¡Œç•Œé¢
    aura.run_cli()

if __name__ == "__main__":
    main()
