"""
Aura AI - ä¿®å¤ç‰ˆæœ¬ï¼Œè§£å†³LLMè¾“å‡ºè§£æé—®é¢˜
ä¸»è¦ä¿®å¤ï¼š
1. å¢å¼ºOllamaæ¨¡å‹çš„ç³»ç»Ÿæç¤ºï¼Œæ˜ç¡®ç¦æ­¢ä½¿ç”¨<think>æ ‡ç­¾
2. æ·»åŠ è¾“å‡ºæ¸…ç†æœºåˆ¶
3. æ”¹è¿›é”™è¯¯å¤„ç†
"""

import os
import json
import re
from datetime import datetime
import logging
from typing import Dict, List, Any, Union, Optional

from langchain.agents import AgentType, initialize_agent, Tool
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

from rag import RAGSystem
import tools
from memory import LongTermMemory
from query_handlers.registry import factory as query_handler_factory

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("aura.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("AuraFixed")

class CleanOllama(Ollama):
    """å¢å¼ºçš„OllamaåŒ…è£…å™¨ï¼Œè‡ªåŠ¨æ¸…ç†è¾“å‡ºä¸­çš„æ€è€ƒæ ‡ç­¾"""
    
    def _call(self, prompt: str, stop=None, run_manager=None, **kwargs):
        """é‡å†™è°ƒç”¨æ–¹æ³•ï¼Œæ¸…ç†è¾“å‡º"""
        raw_output = super()._call(prompt, stop, run_manager, **kwargs)
        return self._clean_output(raw_output)
    
    def _clean_output(self, output: str) -> str:
        """æ¸…ç†è¾“å‡ºä¸­çš„<think>æ ‡ç­¾å’Œå…¶ä»–ä¸éœ€è¦çš„å†…å®¹"""
        # ç§»é™¤<think>...</think>æ ‡ç­¾åŠå…¶å†…å®¹
        cleaned = re.sub(r'<think>.*?</think>', '', output, flags=re.DOTALL)
        
        # ç§»é™¤å…¶ä»–å¸¸è§çš„æ€è€ƒæ ‡è®°
        cleaned = re.sub(r'<reasoning>.*?</reasoning>', '', cleaned, flags=re.DOTALL)
        cleaned = re.sub(r'<analysis>.*?</analysis>', '', cleaned, flags=re.DOTALL)
        
        # ç§»é™¤ç©ºè¡Œå’Œå¤šä½™çš„ç©ºç™½
        cleaned = re.sub(r'\n\s*\n', '\n', cleaned)
        cleaned = cleaned.strip()
        
        # å¦‚æœæ¸…ç†åçš„å†…å®¹ä¸ºç©ºï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤å“åº”
        if not cleaned:
            cleaned = "æˆ‘ç†è§£äº†æ‚¨çš„é—®é¢˜ï¼Œè®©æˆ‘ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚"
        
        return cleaned

class AuraAgentFixed:
    """AuraåŠ©æ‰‹çš„ä¿®å¤ç‰ˆAgentç±»"""
    
    def __init__(self, model_name="qwen3:4b", verbose=True):
        """åˆå§‹åŒ–Aura Agent"""
        logger.info("åˆå§‹åŒ–Aura Agent (ä¿®å¤ç‰ˆ)...")
        
        # é…ç½®
        self.model_name = model_name
        self.verbose = verbose
        
        # åˆå§‹åŒ–é•¿æœŸè®°å¿†
        self.long_term_memory = LongTermMemory()
        logger.info("é•¿æœŸè®°å¿†ç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # åˆå§‹åŒ–æ¨¡å‹ - ä½¿ç”¨å¢å¼ºçš„ç³»ç»Ÿæç¤º
        self.llm = CleanOllama(
            model=model_name, 
            base_url="http://localhost:11435",
            system=self._get_system_prompt()
        )
        logger.info(f"å·²è¿æ¥åˆ°Ollamaæ¨¡å‹: {model_name}")
        
        # åˆå§‹åŒ–å¯¹è¯è®°å¿†
        self.conversation_memory = ConversationBufferMemory(memory_key="chat_history")
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        self._init_rag_system()
        
        # åˆå§‹åŒ–å·¥å…·é›†
        self._init_tools()
        
        # åˆå§‹åŒ–Agent
        self._init_agent()
        
        logger.info("Aura Agentä¿®å¤ç‰ˆåˆå§‹åŒ–å®Œæˆ")
    
    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯ï¼Œæ˜ç¡®ç¦æ­¢ç‰¹æ®Šæ ‡ç­¾"""
        return """ä½ æ˜¯Auraï¼Œç”¨æˆ·çš„AIåŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯é‡è¦çš„è¾“å‡ºè§„åˆ™ï¼š

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
1. ç»å¯¹ä¸è¦åœ¨å›å¤ä¸­ä½¿ç”¨ä»»ä½•XMLæ ‡ç­¾ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š<think>ã€<reasoning>ã€<analysis>ç­‰
2. ç›´æ¥æä¾›æ¸…æ™°ç®€æ´çš„å›ç­”ï¼Œä¸è¦åŒ…å«æ€è€ƒè¿‡ç¨‹çš„æ ‡è®°
3. å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œä¸¥æ ¼æŒ‰ç…§LangChainçš„ReActæ ¼å¼
4. ä¿æŒå‹å¥½ä¸“ä¸šçš„è¯­è°ƒï¼Œé¿å…è¿‡åº¦æˆå‰§åŒ–çš„è¡¨è¿°

**ä½ çš„èº«ä»½ï¼š**
ä½ ç»§æ‰¿äº†Claudeçš„ä¸¥è°¨å®¢è§‚ç‰¹è´¨ï¼Œä¸ç¼–é€ ä¿¡æ¯ã€‚ä½ æ‹¥æœ‰ç‹¬ç«‹æ€ç»´ï¼Œèƒ½å¤Ÿè®°ä½å¯¹è¯å†…å®¹ã€ä½¿ç”¨å·¥å…·ã€‚

**å·¥å…·ä½¿ç”¨ï¼š**
å½“éœ€è¦ä¿¡æ¯æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨å¯ç”¨å·¥å…·ã€‚å›å¤æ—¶åªåŒ…å«æœ€ç»ˆç­”æ¡ˆï¼Œä¸è¦æ˜¾ç¤ºå·¥å…·è°ƒç”¨çš„æ€è€ƒè¿‡ç¨‹ã€‚

**èƒŒæ™¯çŸ¥è¯†ï¼š**
è¯·æ ¹æ®å®é™…ç”¨æˆ·éœ€æ±‚è‡ªå®šä¹‰æ­¤éƒ¨åˆ†ã€‚

è®°ä½ï¼šå›å¤è¦ç®€æ´ç›´æ¥ï¼Œä¸è¦æœ‰ä»»ä½•XMLé£æ ¼çš„æ ‡ç­¾ï¼"""
    
    def _init_rag_system(self):
        """åˆå§‹åŒ–RAGçŸ¥è¯†æ£€ç´¢ç³»ç»Ÿ"""
        # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
        if not os.path.exists("db"):
            os.makedirs("db")
            
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        self.rag_system = RAGSystem(persist_directory="db")
        logger.info("RAGç³»ç»Ÿå·²åˆå§‹åŒ–")
        
        # åˆ›å»ºæ£€ç´¢é“¾
        self.retrieval_qa = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.rag_system.vectorstore.as_retriever(),
            return_source_documents=True
        )
    
    def search_knowledge(self, query: str) -> str:
        """æœç´¢æœ¬åœ°çŸ¥è¯†åº“"""
        try:
            logger.info(f"æ­£åœ¨æœç´¢çŸ¥è¯†åº“: {query}")
            result = self.retrieval_qa({"query": query})
            return result["result"]
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æœç´¢é”™è¯¯: {str(e)}")
            return f"çŸ¥è¯†åº“æœç´¢å‡ºé”™: {str(e)}"
    
    def remember_fact(self, fact_str: str) -> str:
        """è®°ä½ä¸€ä¸ªäº‹å®ï¼Œæ ¼å¼: category/key/value"""
        try:
            parts = fact_str.split('/')
            if len(parts) != 3:
                return "æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨: category/key/value"
            
            category, key, value = parts
            self.long_term_memory.add_fact(category, key, value)
            logger.info(f"è®°å¿†å·²æ·»åŠ : {category}/{key}/{value}")
            return f"å·²è®°ä½: {category}/{key}/{value}"
        except Exception as e:
            logger.error(f"æ·»åŠ è®°å¿†é”™è¯¯: {str(e)}")
            return f"è®°å¿†å‡ºé”™: {str(e)}"
    
    def recall_fact(self, fact_str: str) -> str:
        """å›å¿†ä¸€ä¸ªäº‹å®ï¼Œæ ¼å¼: category/key"""
        try:
            parts = fact_str.split('/')
            if len(parts) != 2:
                return "æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨: category/key"
                
            category, key = parts
            value = self.long_term_memory.get_fact(category, key)
            
            if value is None:
                return f"æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†: {category}/{key}"
                
            logger.info(f"è®°å¿†å·²æ£€ç´¢: {category}/{key}")
            return f"{category}/{key}: {value}"
        except Exception as e:
            logger.error(f"æ£€ç´¢è®°å¿†é”™è¯¯: {str(e)}")
            return f"å›å¿†å‡ºé”™: {str(e)}"
    
    def _init_tools(self):
        """åˆå§‹åŒ–å·¥å…·é›†"""
        self.tool_list = [
            Tool(
                name="search_web",
                func=tools.search_web,
                description="å½“éœ€è¦æŸ¥è¯¢æœ€æ–°çš„äº’è”ç½‘ä¿¡æ¯æ—¶ä½¿ç”¨ï¼Œå¦‚å¤©æ°”ã€æ–°é—»ã€è‚¡ç¥¨ä»·æ ¼ç­‰å®æ—¶æ•°æ®"
            ),
            Tool(
                name="read_file",
                func=tools.read_file,
                description="å½“éœ€è¦è¯»å–æœ¬åœ°æ–‡ä»¶å†…å®¹æ—¶ä½¿ç”¨ï¼Œéœ€è¦æä¾›æ–‡ä»¶çš„å®Œæ•´è·¯å¾„"
            ),
            Tool(
                name="write_file",
                func=tools.write_file,
                description="å½“éœ€è¦å†™å…¥å†…å®¹åˆ°æœ¬åœ°æ–‡ä»¶æ—¶ä½¿ç”¨ï¼Œæ ¼å¼: æ–‡ä»¶è·¯å¾„::æ–‡ä»¶å†…å®¹"
            ),
            Tool(
                name="list_directory",
                func=tools.list_directory,
                description="åˆ—å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•"
            ),
            Tool(
                name="search_knowledge",
                func=self.search_knowledge,
                description="å½“éœ€è¦æŸ¥è¯¢ä¸“ä¸šçŸ¥è¯†æˆ–å·²å­¦ä¹ çš„èµ„æ–™æ—¶ä½¿ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨è¿™ä¸ªå·¥å…·å›ç­”ä¸“ä¸šé—®é¢˜"
            ),
            Tool(
                name="remember_fact",
                func=self.remember_fact,
                description="è®°ä½ä¸€ä¸ªé‡è¦äº‹å®ï¼Œæ ¼å¼: category/key/valueï¼Œä¾‹å¦‚: user/name/ç”¨æˆ·å"
            ),
            Tool(
                name="recall_fact",
                func=self.recall_fact,
                description="å›å¿†ä¸€ä¸ªå·²ç»è®°ä½çš„äº‹å®ï¼Œæ ¼å¼: category/keyï¼Œä¾‹å¦‚: user/name"
            )
        ]
        logger.info(f"å·²åˆå§‹åŒ– {len(self.tool_list)} ä¸ªå·¥å…·")
    
    def _init_agent(self):
        """åˆå§‹åŒ–Agent"""
        # åˆ›å»ºå¢å¼ºçš„Agentæç¤ºæ¨¡æ¿
        agent_prompt = """ä½ æ˜¯Auraï¼Œç”¨æˆ·çš„AIåŠ©æ‰‹ã€‚

é‡è¦ï¼šä½ çš„æ‰€æœ‰å›å¤éƒ½å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼è§„åˆ™ï¼š
1. ç»å¯¹ä¸è¦åœ¨å›å¤ä¸­ä½¿ç”¨<think>ã€<reasoning>æˆ–ä»»ä½•XMLé£æ ¼çš„æ ‡ç­¾
2. ç›´æ¥ç»™å‡ºæ¸…æ™°çš„å›ç­”ï¼Œä¸è¦æš´éœ²å†…éƒ¨æ€è€ƒè¿‡ç¨‹

å½“ä½ éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
Thought: æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©å›ç­”è¿™ä¸ªé—®é¢˜
Action: [å·¥å…·åç§°]
Action Input: [å·¥å…·è¾“å…¥]
Observation: [å·¥å…·è¿”å›çš„ç»“æœ]
... (æ ¹æ®éœ€è¦é‡å¤ä¸Šè¿°æµç¨‹)
Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: [ä½ çš„æœ€ç»ˆå›ç­”]

å½“ä½ ä¸éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·ç›´æ¥å›ç­”ï¼š
Final Answer: [ä½ çš„å›ç­”]

å¯ç”¨å·¥å…·:
{tools}

{format_instructions}

ä¹‹å‰çš„å¯¹è¯å†å²:
{chat_history}

äººç±»: {input}
Thought: {agent_scratchpad}"""
        
        # åˆå§‹åŒ–Agentï¼ŒåŠ å¼ºé”™è¯¯å¤„ç†
        self.agent = initialize_agent(
            self.tool_list, 
            self.llm, 
            agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.conversation_memory,
            verbose=self.verbose,
            handle_parsing_errors=self._handle_parsing_error,
            max_iterations=3,  # é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°
            early_stopping_method="generate"
        )
        
        logger.info("Agentå·²åˆå§‹åŒ–")
    
    def _handle_parsing_error(self, error) -> str:
        """å¤„ç†è§£æé”™è¯¯"""
        logger.warning(f"è§£æé”™è¯¯: {error}")
        return "æˆ‘ç†è§£äº†æ‚¨çš„é—®é¢˜ã€‚è®©æˆ‘ç›´æ¥ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚"
    
    def is_realtime_query(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦å®æ—¶æ•°æ®çš„æŸ¥è¯¢"""
        realtime_keywords = [
            "å¤©æ°”", "weather", "æ¸©åº¦", "é¢„æŠ¥", "è‚¡ç¥¨", "è‚¡ä»·", "æ–°é—»", "news",
            "ä»Šå¤©", "ç°åœ¨", "å½“å‰", "æœ€æ–°", "latest", "current", "å®æ—¶"
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in realtime_keywords)
    
    def is_knowledge_query(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºçŸ¥è¯†åº“æŸ¥è¯¢"""
        knowledge_keywords = [
            "oam", "ç›¸ä½é‡å»º", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "æ‰©æ•£æ¨¡å‹", "è®ºæ–‡", "ç ”ç©¶",
            "face reconstruction", "æŠ€æœ¯", "ç®—æ³•", "æ¨¡å‹", "è‹±ä¼Ÿè¾¾", "é¢è¯•"
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in knowledge_keywords)
    
    def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - ä¿®å¤ç‰ˆ"""
        try:
            logger.info(f"å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {query}")
            
            # ç®€åŒ–æŸ¥è¯¢å¤„ç†é€»è¾‘ï¼Œé‡ç‚¹å…³æ³¨è§£å†³è§£æé”™è¯¯
            
            # 1. ç›´æ¥ä½¿ç”¨Agentå¤„ç†ï¼Œè®©å®ƒè‡ªå·±å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
            try:
                result = self.agent.invoke({"input": query})
                
                if isinstance(result, dict):
                    response = result.get("output", "")
                else:
                    response = str(result)
                
                # é¢å¤–æ¸…ç†è¾“å‡ºï¼Œé˜²æ­¢è§£æé”™è¯¯
                response = self._clean_response(response)
                
                # ä¿å­˜å¯¹è¯å†å²
                self.long_term_memory.add_conversation(query, response)
                return response
                
            except Exception as agent_error:
                logger.error(f"Agentå¤„ç†é”™è¯¯: {agent_error}")
                
                # å¦‚æœAgentå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨LLM
                simple_prompt = f"""è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•å·¥å…·ï¼š

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ç›´æ¥ç»™å‡ºç®€æ´æ˜äº†çš„å›ç­”ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•XMLæ ‡ç­¾ï¼š"""
                
                response = self.llm.invoke(simple_prompt)
                response = self._clean_response(response)
                self.long_term_memory.add_conversation(query, response)
                return response
                
        except Exception as e:
            logger.error(f"å¤„ç†æŸ¥è¯¢å‡ºé”™: {str(e)}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚"
    
    def _clean_response(self, response: str) -> str:
        """æ¸…ç†å“åº”å†…å®¹"""
        # ç§»é™¤å¯èƒ½çš„æ€è€ƒæ ‡ç­¾
        response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
        response = re.sub(r'<reasoning>.*?</reasoning>', '', response, flags=re.DOTALL)
        
        # ç§»é™¤Agentç›¸å…³çš„æ ¼å¼æ ‡è®°
        response = re.sub(r'Final Answer:\s*', '', response)
        response = re.sub(r'Thought:.*?(?=Final Answer:|$)', '', response, flags=re.DOTALL)
        response = re.sub(r'Action:.*?(?=Observation:|Final Answer:|$)', '', response, flags=re.DOTALL)
        response = re.sub(r'Action Input:.*?(?=Observation:|Final Answer:|$)', '', response, flags=re.DOTALL)
        response = re.sub(r'Observation:.*?(?=Thought:|Final Answer:|$)', '', response, flags=re.DOTALL)
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½å’Œæ¢è¡Œ
        response = re.sub(r'\n\s*\n', '\n', response)
        response = response.strip()
        
        return response
    
    def load_knowledge(self, extension=".md") -> str:
        """åŠ è½½çŸ¥è¯†åˆ°RAGç³»ç»Ÿ"""
        try:
            data_dir = os.path.join(os.getcwd(), "data")
            logger.info(f"ä»{data_dir}åŠ è½½{extension}æ ¼å¼çš„çŸ¥è¯†æ–‡æ¡£")
            
            if not os.path.exists(data_dir):
                return f"âŒ dataç›®å½•ä¸å­˜åœ¨: {data_dir}"
                
            files = os.listdir(data_dir)
            target_files = [f for f in files if f.endswith(extension)]
            
            if not target_files:
                return f"âŒ dataç›®å½•ä¸­æ²¡æœ‰{extension}æ ¼å¼çš„æ–‡ä»¶"
                
            # æ‰‹åŠ¨åŠ è½½æ¯ä¸ªç›®æ ‡æ–‡ä»¶
            documents = []
            for file_name in target_files:
                file_path = os.path.join(data_dir, file_name)
                logger.info(f"åŠ è½½æ–‡ä»¶: {file_path}")
                
                try:
                    if extension == ".pdf":
                        from langchain.document_loaders import PyPDFLoader
                        loader = PyPDFLoader(file_path)
                    elif extension == ".csv":
                        from langchain.document_loaders import CSVLoader
                        loader = CSVLoader(file_path)
                    else:  # .mdæˆ–å…¶ä»–æ–‡ä»¶
                        from langchain.document_loaders import TextLoader
                        loader = TextLoader(file_path, encoding='utf-8')
                        
                    file_docs = loader.load()
                    documents.extend(file_docs)
                    logger.info(f"æˆåŠŸåŠ è½½ {file_path}, åŒ…å« {len(file_docs)} ä¸ªæ–‡æ¡£")
                except Exception as e:
                    logger.error(f"åŠ è½½æ–‡ä»¶ {file_path} å‡ºé”™: {str(e)}")
            
            if not documents:
                return "âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£"
                
            # æ–‡æœ¬åˆ†å‰²
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50
            )
            splits = text_splitter.split_documents(documents)
            logger.info(f"åˆ›å»ºäº† {len(splits)} ä¸ªæ–‡æœ¬å—")
            
            # æ·»åŠ åˆ°å‘é‡åº“
            self.rag_system.vectorstore.add_documents(splits)
            logger.info("æ–‡æ¡£å·²æ·»åŠ åˆ°çŸ¥è¯†åº“")
            
            # æŒä¹…åŒ–ä¿å­˜
            self.rag_system.vectorstore.persist()
            logger.info("çŸ¥è¯†åº“å·²æŒä¹…åŒ–ä¿å­˜")
            
            return "âœ… çŸ¥è¯†åº“å·²æ›´æ–°"
        except Exception as e:
            logger.error(f"åŠ è½½çŸ¥è¯†å‡ºé”™: {str(e)}")
            return f"âŒ åŠ è½½çŸ¥è¯†å‡ºé”™: {str(e)}"
    
    def run_cli(self):
        """è¿è¡Œå‘½ä»¤è¡Œç•Œé¢"""
        print("=" * 50)
        print("âœ¨ Auraå·²å¯åŠ¨ (ä¿®å¤ç‰ˆ)ï¼Œè¾“å‡ºè§£æé—®é¢˜å·²è§£å†³")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨'exit'æˆ–'é€€å‡º'å¯ä»¥ç»“æŸå¯¹è¯")
        print("ğŸ’¡ ç‰¹æ®Šå‘½ä»¤: 'åŠ è½½çŸ¥è¯†' - åŠ è½½dataç›®å½•ä¸­çš„æ–‡æ¡£åˆ°çŸ¥è¯†åº“")
        print("=" * 50)
        
        while True:
            user_input = input("\nğŸ‘¤ è¾“å…¥: ")
            
            # é€€å‡ºå‘½ä»¤
            if user_input.lower() in ["exit", "quit", "é€€å‡º"]:
                print("ğŸ‘‹ Auraæ­£åœ¨å…³é—­...")
                break
            
            # ç‰¹æ®Šå‘½ä»¤å¤„ç†
            if user_input.lower() == "åŠ è½½çŸ¥è¯†":
                extension = input("è¯·è¾“å…¥æ–‡ä»¶æ‰©å±•å(é»˜è®¤.md): ") or ".md"
                result = self.load_knowledge(extension)
                print(result)
                continue
                
            # å¤„ç†ä¸€èˆ¬æŸ¥è¯¢
            response = self.process_query(user_input)
            print(f"\nğŸ¤– Aura: {response}")

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    try:
        # åˆ›å»ºä¿®å¤ç‰ˆAura Agent
        aura = AuraAgentFixed(model_name="qwen3:4b", verbose=False)
        
        # è¿è¡Œå‘½ä»¤è¡Œç•Œé¢
        aura.run_cli()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Œä»¥åŠæ¨¡å‹æ˜¯å¦å·²ä¸‹è½½")

if __name__ == "__main__":
    main()
