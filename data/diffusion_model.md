# Diffusion模型详解

## 基础原理

Diffusion模型的核心思想是通过一个逐步添加噪声的正向过程和一个逐步去噪的反向过程来生成数据。

### 正向过程（Forward Process）
- 从一个清晰的图像x₀开始
- 通过T个时间步逐渐添加高斯噪声
- 每一步t对应一个噪声程度q(xₜ|xₜ₋₁)
- 最终将图像完全转变为纯随机噪声xₜ

### 反向过程（Reverse Process）
- 从纯噪声xₜ开始
- 训练神经网络预测去噪方向p(xₜ₋₁|xₜ)
- 逐步去噪直到得到生成图像x₀

## 模型架构

### U-Net结构
- **编码器-解码器**架构
- 编码器：通过下采样提取图像特征
- 解码器：通过上采样重建图像
- 中间有跳跃连接(skip connections)保留细节信息

### 时间嵌入（Time Embedding）
- 将噪声步骤(t)编码为网络可理解的向量
- 通常使用正弦位置编码(sinusoidal position encoding)实现
- 时间信息被注入到U-Net的各层中

### 注意力模块（Attention）
- 在U-Net的中间层加入自注意力机制
- 帮助模型捕捉图像中远距离的依赖关系
- Stable Diffusion中使用交叉注意力将文本特征融入图像生成

## 训练目标

### 噪声预测
- 网络ε_θ预测添加的噪声
- 损失函数：L = E[||ε - ε_θ(xₜ, t)||²]

### 图像预测
- 网络直接预测原始图像x₀
- 或预测均值和方差以重建前一步状态

## 应用与变体

### Latent Diffusion Model (LDM)
- 在VAE压缩的潜在空间中进行扩散过程
- 计算效率更高，可处理更高分辨率图像
- Stable Diffusion正是基于此方法

### 条件生成
- 通过交叉注意力机制注入条件信息
- 可以是文本、类别、图像等
- 实现文本引导的图像生成

### 采样技术
- DDPM：原始但较慢的采样方法
- DDIM：加速版本，允许更少步骤生成
- DPM-Solver：基于ODE的快速采样器

## 与其他技术的关联

### CLIP集成
- 使用CLIP文本编码器提取提示词特征
- 通过交叉注意力将文本特征融入U-Net
- 在条件Diffusion中实现文本到图像的映射

### LoRA适配
- 通过低秩分解适配预训练Diffusion模型
- 高效微调U-Net中的权重
- 可以用于个性化定制和风格适应

### 控制技术
- ControlNet：为Diffusion模型添加额外控制条件
- Img2Img：从已有图像开始扩散
- Inpainting：只对图像特定区域进行扩散

## 优势与挑战

### 优势
- 高质量生成能力
- 灵活的条件控制
- 样本多样性好

### 挑战
- 计算成本高
- 采样速度慢
- 需要大量训练数据
